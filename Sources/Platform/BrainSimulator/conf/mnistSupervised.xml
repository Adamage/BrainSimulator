<?xml version="1.0" encoding="utf-8"?>
<network
  inputwidth="28" inputheight="28" inputcount="1" samplesperstep="1"
	outputMinValue="0" outputMaxValue="1" outputColumnHint="10"
	>
	<convolutionLayer 	nbFeatures="8" 	patchWidth="5" patchHeight="5" />
	<activationLayer 	function="RELU" />
	<poolLayer 			stride="2" 		rule="MAX" />
	<convolutionLayer 	nbFeatures="16" patchWidth="5" patchHeight="5" />
	<activationLayer 	function="RELU" />
	<poolLayer 			stride="2" 		rule="MAX" />
	<neuronLayer 		nbNeurons="10" />
	<softmaxLayer />
</network>
